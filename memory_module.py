# memory_module.py - VERS√ÉO COMPLETA COM MEM√ìRIA INTELIGENTE
"""
 M√≥dulo de Mem√≥ria Inteligente do ChatFiscal

Combina:
- Mem√≥ria Compartilhada (thread-safe)
- Mem√≥ria Dedicada (por m√≥dulo)
- Mem√≥ria Inteligente com FAISS (busca sem√¢ntica)
- Persist√™ncia local em disco
"""

import os
import pickle
import json
import threading
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
from langchain_core.documents import Document
import numpy as np
from difflib import SequenceMatcher

# Tenta importar FAISS e HuggingFace, mas oferece fallback se n√£o dispon√≠vel
try:
    import faiss
    from langchain_community.embeddings import HuggingFaceEmbeddings
    HAVE_FAISS = True
    logger.info("‚úÖ FAISS dispon√≠vel - usando busca vetorial")
except ImportError:
    HAVE_FAISS = False
    logger.warning("‚ö†Ô∏è FAISS n√£o dispon√≠vel - usando fallback com busca por similaridade de string")

# Configura√ß√£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('memory_chatfiscal.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class SimpleStringEmbeddings:
    """Fallback simples quando HuggingFace/FAISS n√£o est√£o dispon√≠veis."""
    
    def embed_query(self, text: str) -> List[float]:
        """Retorna uma representa√ß√£o simples do texto como vetor."""
        # Usa um hash do texto normalizado como embedding
        # N√£o √© sem√¢ntico, mas permite matching b√°sico
        norm_text = text.lower().strip()
        hash_val = hash(norm_text)
        # Converte o hash em uma lista de 10 n√∫meros
        return [(hash_val >> i) & 0xFF for i in range(0, 80, 8)]
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """Embeddings para m√∫ltiplos textos."""
        return [self.embed_query(text) for text in texts]


class SimpleVectorStore:
    """Armazenamento vetorial simples usando similaridade de string."""
    
    def __init__(self, dimension: int = 10):
        self.texts = []  # armazena textos originais
        self.vectors = []  # armazena vetores (hashes)
    
    def add(self, vectors: np.ndarray):
        """Adiciona vetores ao store."""
        if isinstance(vectors, np.ndarray):
            vectors = vectors.tolist()
        if not isinstance(vectors, list):
            vectors = [vectors]
        self.vectors.extend(vectors)
    
    def search(self, query_vector: np.ndarray, k: int = 4) -> tuple:
        """Busca os k vetores mais similares."""
        if isinstance(query_vector, np.ndarray):
            query_vector = query_vector.tolist()
        
        # Usa SequenceMatcher para comparar strings
        scores = []
        for vec in self.vectors:
            score = SequenceMatcher(None, str(query_vector), str(vec)).ratio()
            scores.append(score)
        
        # Retorna os k √≠ndices mais similares
        indices = np.argsort(scores)[-k:][::-1]
        return indices, [scores[i] for i in indices]


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 1Ô∏è‚É£ MEM√ìRIA COMPARTILHADA (Thread-Safe)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
class MemoriaCompartilhada:
    """
    Mem√≥ria compartilhada entre m√≥dulos com thread-safety.
    Ideal para dados globais: arquivos carregados, configura√ß√µes, cache.
    """
    
    def __init__(self):
        self.dados: Dict[str, Any] = {}
        self.lock = threading.Lock()
        logger.info("‚úÖ MemoriaCompartilhada inicializada")
    
    def salvar(self, chave: str, valor: Any) -> None:
        """Salva um valor de forma thread-safe."""
        with self.lock:
            self.dados[chave] = valor
            logger.debug(f"üíæ Salvo: {chave}")
    
    def obter(self, chave: str) -> Optional[Any]:
        """Obt√©m um valor de forma thread-safe."""
        with self.lock:
            return self.dados.get(chave)
    
    def listar_chaves(self) -> List[str]:
        """Retorna todas as chaves dispon√≠veis."""
        with self.lock:
            return list(self.dados.keys())
    
    def limpar(self, chave: Optional[str] = None) -> None:
        """Limpa uma chave espec√≠fica ou toda a mem√≥ria."""
        with self.lock:
            if chave:
                self.dados.pop(chave, None)
                logger.info(f"üóëÔ∏è Chave removida: {chave}")
            else:
                self.dados.clear()
                logger.info("üóëÔ∏è Mem√≥ria compartilhada limpa")
    
    def __len__(self) -> int:
        """Retorna quantidade de chaves armazenadas."""
        with self.lock:
            return len(self.dados)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 2Ô∏è‚É£ MEM√ìRIA DEDICADA (Isolada por M√≥dulo)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
class MemoriaDedicada:
    """
    Mem√≥ria isolada para cada m√≥dulo espec√≠fico.
    N√£o possui thread-lock (usa apenas no contexto local).
    """
    
    def __init__(self, nome_modulo: str = "default"):
        self.dados: Dict[str, Any] = {}
        self.nome_modulo = nome_modulo
        logger.info(f"‚úÖ MemoriaDedicada [{nome_modulo}] inicializada")
    
    def salvar(self, chave: str, valor: Any) -> None:
        """Salva um valor na mem√≥ria dedicada."""
        self.dados[chave] = valor
        logger.debug(f"üíæ [{self.nome_modulo}] Salvo: {chave}")
    
    def obter(self, chave: str) -> Optional[Any]:
        """Obt√©m um valor da mem√≥ria dedicada."""
        return self.dados.get(chave)
    
    def listar_chaves(self) -> List[str]:
        """Retorna todas as chaves dispon√≠veis."""
        return list(self.dados.keys())
    
    def limpar(self, chave: Optional[str] = None) -> None:
        """Limpa uma chave espec√≠fica ou toda a mem√≥ria."""
        if chave:
            self.dados.pop(chave, None)
            logger.info(f"üóëÔ∏è [{self.nome_modulo}] Chave removida: {chave}")
        else:
            self.dados.clear()
            logger.info(f"üóëÔ∏è [{self.nome_modulo}] Mem√≥ria limpa")
    
    def __len__(self) -> int:
        """Retorna quantidade de chaves armazenadas."""
        return len(self.dados)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 3Ô∏è‚É£ MEM√ìRIA INTELIGENTE (FAISS + Hist√≥rico + Persist√™ncia)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
class MemoriaInteligente:
    """
    üß† Mem√≥ria Inteligente com busca sem√¢ntica usando FAISS.
    
    Funcionalidades:
    - Armazena hist√≥rico de perguntas e respostas
    - Indexa conversas com embeddings vetoriais
    - Busca contexto relevante por similaridade sem√¢ntica
    - Persist√™ncia local em disco
    - Integra√ß√£o com Streamlit Session State
    """
    
    def __init__(self, persist_dir: str = "memory_store", model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        """
        Inicializa a mem√≥ria inteligente.
        
        Args:
            persist_dir: Diret√≥rio para persist√™ncia dos dados
            model_name: Modelo de embeddings HuggingFace
        """
        self.persist_dir = persist_dir
        self.model_name = model_name
        os.makedirs(persist_dir, exist_ok=True)
        
        # Caminhos de persist√™ncia
        self.index_path = os.path.join(persist_dir, "faiss.index")
        self.meta_path = os.path.join(persist_dir, "metadados.pkl")
        self.historico_path = os.path.join(persist_dir, "historico.json")
        
        # Inicializa√ß√£o de embeddings
        try:
            if HAVE_FAISS:
                self.embeddings = HuggingFaceEmbeddings(model_name=model_name)
                logger.info(f"‚úÖ Embeddings HuggingFace carregados: {model_name}")
            else:
                self.embeddings = SimpleStringEmbeddings()
                logger.info("‚úÖ Usando embeddings simples (fallback)")
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar embeddings: {e}")
            self.embeddings = SimpleStringEmbeddings()
            logger.warning("‚ö†Ô∏è Fallback para embeddings simples ap√≥s erro")
        
        # Estruturas de dados
        self.historico: List[Dict[str, Any]] = []
        self.metadados: List[Dict[str, Any]] = []
        self.index = None
        self.dimension: Optional[int] = None
        
        # Thread-safety
        self.lock = threading.Lock()
        
        # Carrega dados persistentes (se existirem)
        self._carregar_memoria()
        
        logger.info(f"‚úÖ MemoriaInteligente inicializada | Registros: {len(self.historico)}")
    
    def salvar_contexto(self, pergunta: str, resposta: str, metadados_extras: Optional[Dict] = None) -> None:
        """Armazena par pergunta-resposta + embedding FAISS."""
        with self.lock:
            try:
                texto_completo = f"Pergunta: {pergunta}\nResposta: {resposta}"
                vetor = self.embeddings.embed_query(texto_completo)
                vetor_np = np.array([vetor], dtype="float32")
                
                if self.index is None:
                    self.dimension = len(vetor)
                    if HAVE_FAISS:
                        self.index = faiss.IndexFlatL2(self.dimension)
                    else:
                        self.index = SimpleVectorStore(dimension=self.dimension)
                    logger.info(f"üîß √çndice FAISS criado | Dimens√£o: {self.dimension}")
                
                self.index.add(vetor_np)
                
                registro = {
                    "pergunta": pergunta,
                    "resposta": resposta,
                    "timestamp": datetime.now().isoformat(),
                    "id": len(self.metadados)
                }
                
                if metadados_extras:
                    registro.update(metadados_extras)
                
                self.metadados.append(registro)
                self.historico.append(registro)
                self._salvar_memoria()
                
                logger.info(f"üíæ Contexto salvo | Total: {len(self.historico)}")
                
            except Exception as e:
                logger.error(f"‚ùå Erro ao salvar contexto: {e}")
    
    def buscar_contexto_relevante(self, consulta: str, k: int = 3, threshold: float = 1.5) -> str:
        """Retorna contexto mais relevante semanticamente."""
        with self.lock:
            if not self.index or self.index.ntotal == 0:
                logger.warning("‚ö†Ô∏è √çndice FAISS vazio")
                return ""
            
            try:
                vetor = self.embeddings.embed_query(consulta)
                vetor_np = np.array([vetor], dtype="float32")
                distancias, indices = self.index.search(vetor_np, min(k, self.index.ntotal))
                
                contexto_partes = []
                for dist, idx in zip(distancias[0], indices[0]):
                    if idx < len(self.metadados) and dist <= threshold:
                        meta = self.metadados[idx]
                        contexto_partes.append(
                            f"üîπ Pergunta: {meta['pergunta']}\n"
                            f"   Resposta: {meta['resposta'][:200]}...\n"
                            f"   [Similaridade: {dist:.3f}]"
                        )
                
                if contexto_partes:
                    logger.info(f"üîç Encontrados {len(contexto_partes)} contextos relevantes")
                    return "\n\n".join(contexto_partes)
                else:
                    logger.info("üîç Nenhum contexto relevante encontrado")
                    return ""
                
            except Exception as e:
                logger.error(f"‚ùå Erro na busca: {e}")
                return ""
    
    def obter_historico(self, ultimos_n: Optional[int] = None) -> List[Dict[str, Any]]:
        """Retorna hist√≥rico completo ou √∫ltimos N registros."""
        with self.lock:
            if ultimos_n:
                return self.historico[-ultimos_n:]
            return self.historico.copy()
    
    def obter_historico_formatado(self, ultimos_n: int = 5) -> str:
        """Retorna hist√≥rico formatado para exibi√ß√£o ou envio √† LLM."""
        historico = self.obter_historico(ultimos_n)
        
        if not historico:
            return "Nenhum hist√≥rico dispon√≠vel."
        
        linhas = ["üìú HIST√ìRICO RECENTE:\n"]
        for i, item in enumerate(historico, 1):
            linhas.append(f"{i}. Pergunta: {item['pergunta']}")
            linhas.append(f"   Resposta: {item['resposta'][:150]}...")
            linhas.append("")
        
        return "\n".join(linhas)
    
    def limpar(self, limpar_disco: bool = True) -> None:
        """Limpa mem√≥ria e opcionalmente remove arquivos persistentes."""
        with self.lock:
            self.historico.clear()
            self.metadados.clear()
            self.index = None
            self.dimension = None
            
            if limpar_disco:
                for caminho in [self.index_path, self.meta_path, self.historico_path]:
                    if os.path.exists(caminho):
                        try:
                            os.remove(caminho)
                            logger.info(f"üóëÔ∏è Removido: {caminho}")
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è Erro ao remover {caminho}: {e}")
            
            logger.info("üóëÔ∏è Mem√≥ria inteligente limpa")
    
    def _salvar_memoria(self) -> None:
        """Persiste FAISS + metadados + hist√≥rico no disco."""
        try:
            if self.index and self.index.ntotal > 0:
                faiss.write_index(self.index, self.index_path)
            
            with open(self.meta_path, "wb") as f:
                pickle.dump({"metadados": self.metadados, "dimension": self.dimension}, f)
            
            with open(self.historico_path, "w", encoding="utf-8") as f:
                json.dump(self.historico, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao salvar mem√≥ria: {e}")
    
    def _carregar_memoria(self) -> None:
        """Carrega FAISS + metadados + hist√≥rico do disco."""
        try:
            if os.path.exists(self.index_path):
                self.index = faiss.read_index(self.index_path)
                logger.info(f"‚úÖ √çndice FAISS carregado: {self.index.ntotal} vetores")
            
            if os.path.exists(self.meta_path):
                with open(self.meta_path, "rb") as f:
                    dados = pickle.load(f)
                    self.metadados = dados.get("metadados", [])
                    self.dimension = dados.get("dimension")
            
            if os.path.exists(self.historico_path):
                with open(self.historico_path, "r", encoding="utf-8") as f:
                    self.historico = json.load(f)
                    
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao carregar mem√≥ria: {e}")
    
    def __len__(self) -> int:
        return len(self.historico)
    
    def estatisticas(self) -> Dict[str, Any]:
        """Retorna estat√≠sticas da mem√≥ria."""
        with self.lock:
            return {
                "total_registros": len(self.historico),
                "total_vetores_faiss": self.index.ntotal if self.index else 0,
                "dimensao_vetor": self.dimension,
                "tamanho_indice_mb": os.path.getsize(self.index_path) / (1024*1024) if os.path.exists(self.index_path) else 0,
                "modelo_embeddings": self.model_name,
                "diretorio_persistencia": self.persist_dir
            }
