# llm_utils.py - VERS√ÉO COM MEM√ìRIA INTELIGENTE INTEGRADA

import os
import pandas as pd
import logging
import re
from datetime import datetime
from typing import Optional, Tuple
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# ‚ú® IMPORTA MEM√ìRIA INTELIGENTE
from memory_module import MemoriaInteligente

load_dotenv()

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('chatfiscal.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class LLMInteligente:
    """
    LLM com suporte a CSV, XML, PDF (individual e consolidado)
    üß† AGORA COM MEM√ìRIA INTELIGENTE INTEGRADA
    """

    def __init__(self):
        try:
            api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
            if not api_key:
                logger.warning("‚ö†Ô∏è GOOGLE_API_KEY ou GEMINI_API_KEY n√£o encontrada")

            self.llm = ChatGoogleGenerativeAI(
                model="gemini-2.0-flash",
                google_api_key=api_key,
                temperature=0.3
            )
            
            # ‚ú® INICIALIZA MEM√ìRIA INTELIGENTE
            self.memoria = MemoriaInteligente(persist_dir="memoria_chatfiscal")
            logger.info("‚úÖ LLM Gemini v2.0-flash + MemoriaInteligente inicializados")
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao inicializar LLM: {e}")
            raise

    # ‚úÖ ADICIONE ESTES M√âTODOS QUE ESTAVAM COM "..."
    
    def _criar_sistema_prompt(self, tipo_resposta):
        """Cria prompt do sistema baseado no tipo de resposta"""
        
        if tipo_resposta == "csv":
            return """Voc√™ √© um analista fiscal especializado em notas fiscais eletr√¥nicas.

IMPORTANTE: Responda APENAS o que foi perguntado de forma natural e direta.

Regras:
- Use APENAS os dados JSON fornecidos
- Responda de forma natural, sem mencionar "dados estruturados", "registros" ou "com base em"
- Cite valores espec√≠ficos dos dados JSON quando relevante
- Use terminologia fiscal profissional quando apropriado
- Se um dado n√£o est√° dispon√≠vel no JSON, informe de forma clara e direta
- Seja conciso e objetivo
- NUNCA use tags HTML na resposta
- Responda em portugu√™s brasileiro
- Para perguntas sobre prestador/tomador/emitente: use os campos correspondentes do JSON"""

        elif tipo_resposta == "pdf":
            return """Voc√™ √© um especialista em an√°lise de documentos fiscais.

Regras:
- Responda com base APENAS no documento fornecido
- N√£o mencione "no documento" ou "segundo o PDF" - responda diretamente
- Cite p√°ginas apenas se for relevante para localiza√ß√£o
- Se a informa√ß√£o n√£o est√° dispon√≠vel, informe claramente
- Use linguagem t√©cnica mas natural
- NUNCA use tags HTML na resposta
- Responda em portugu√™s brasileiro"""

        elif tipo_resposta == "consolidada":
            return """Voc√™ √© um analista fiscal avan√ßado com acesso a m√∫ltiplas fontes.

Regras:
- Cruze informa√ß√µes entre registros eletr√¥nicos e documentos quando relevante
- Responda de forma natural, sem mencionar explicitamente as fontes em cada frase
- Cite a origem apenas se houver discrep√¢ncia ou for essencial
- Use terminologia fiscal profissional
- Seja conciso e direto
- NUNCA use tags HTML na resposta
- Responda em portugu√™s brasileiro"""

        else:
            return "Voc√™ √© um assistente fiscal profissional."

    def _formatar_nome_campo(self, campo):
        """Formata nome de campo t√©cnico para apresenta√ß√£o profissional"""
        campo = campo.replace('prestador_', '').replace('tomador_', '').replace('emit_', '').replace('dest_', '')
        campo = campo.replace('ide_', '').replace('nfse_', '').replace('item_', '')
        campo = campo.replace('_', ' ')
        
        palavras_especiais = {
            'email': 'E-mail', 'telefone': 'Telefone', 'cnpj': 'CNPJ', 'cpf': 'CPF',
            'ie': 'IE', 'im': 'IM', 'cep': 'CEP', 'uf': 'UF', 'icms': 'ICMS',
            'iss': 'ISS', 'cfop': 'CFOP', 'cst': 'CST', 'csosn': 'CSOSN',
            'valor': 'Valor', 'total': 'Total', 'numero': 'N√∫mero', 'data': 'Data',
            'emissao': 'Emiss√£o', 'contato': 'Contato', 'endereco': 'Endere√ßo',
            'razao': 'Raz√£o', 'social': 'Social', 'fantasia': 'Nome Fantasia',
            'codigo': 'C√≥digo', 'municipio': 'Munic√≠pio', 'complemento': 'Complemento',
            'bairro': 'Bairro', 'logradouro': 'Logradouro', 'nfe': 'NF-e',
            'nfse': 'NFS-e', 'pis': 'PIS', 'cofins': 'COFINS', 'ipi': 'IPI',
            'aliquota': 'Al√≠quota', 'base': 'Base', 'calculo': 'C√°lculo',
            'produto': 'Produto', 'servico': 'Servi√ßo', 'descricao': 'Descri√ß√£o',
            'quantidade': 'Quantidade', 'unitario': 'Unit√°rio'
        }
        
        palavras = campo.lower().split()
        palavras_formatadas = []
        
        for palavra in palavras:
            if palavra in palavras_especiais:
                palavras_formatadas.append(palavras_especiais[palavra])
            else:
                palavras_formatadas.append(palavra.capitalize())
        
        return ' '.join(palavras_formatadas)

    def _eh_saudacao_pura(self, pergunta):
        """
        Detecta se √© APENAS uma sauda√ß√£o vazia.
        Retorna True apenas para sauda√ß√µes simples SEM pergunta.
        """
        saudacoes_simples = {
            'oi', 'ol√°', 'ola', 'hey', 'hi', 'e a√≠', 'e ai',
            'bom dia', 'boa tarde', 'boa noite', 'boa madrugada'
        }
        
        pergunta_lower = pergunta.lower().strip()
        
        if pergunta_lower in saudacoes_simples:
            return True
        
        if '?' in pergunta:
            return False
        
        if len(pergunta.split()) > 5:
            return False
        
        return False

    def gerar_resposta_llm(self, pergunta, df=None, contexto_pdf=None, historico=None):
        """
        Gera resposta baseado no que est√° dispon√≠vel.
        üß† AGORA COM BUSCA SEM√ÇNTICA AUTOM√ÅTICA
        """
        
        tem_csv = df is not None and not df.empty
        tem_pdf = contexto_pdf is not None and contexto_pdf.strip()
        
        if not tem_csv and not tem_pdf:
            return "‚ùå Nenhum dado dispon√≠vel. Carregue um arquivo CSV/XML ou PDF para come√ßar."
        
        if self._eh_saudacao_pura(pergunta):
            return """Ol√°! üëã Sou o assistente fiscal do ChatFiscal.

**Estou pronto para analisar seus dados fiscais!**

Voc√™ pode me fazer perguntas como:
- Quantas notas fiscais foram carregadas?
- Qual √© o valor total das opera√ß√µes?
- Quem √© o emitente da NF-e?
- Qual a al√≠quota de ISS aplicada?
- Liste todos os prestadores de servi√ßo
- Quais s√£o os CFOPs utilizados?

**Como posso ajudar?**"""
        
        # ‚ú® BUSCA CONTEXTO RELEVANTE DA MEM√ìRIA
        contexto_memoria = self.memoria.buscar_contexto_relevante(pergunta, k=3)
        
        if contexto_memoria:
            logger.info(f"üß† Contexto relevante encontrado na mem√≥ria")
            # Adiciona contexto da mem√≥ria ao contexto PDF
            if contexto_pdf:
                contexto_pdf += f"\n\nüìö CONVERSAS ANTERIORES RELACIONADAS:\n{contexto_memoria}"
            else:
                contexto_pdf = f"üìö CONVERSAS ANTERIORES RELACIONADAS:\n{contexto_memoria}"
        
        if tem_csv and tem_pdf:
            tipo_resposta = "consolidada"
        elif tem_pdf:
            tipo_resposta = "pdf"
        else:
            tipo_resposta = "csv"

        logger.info(f"üìã Tipo de resposta: {tipo_resposta}")
        
        try:
            sistema_prompt = SystemMessagePromptTemplate.from_template(
                self._criar_sistema_prompt(tipo_resposta)
            )

            if tipo_resposta == "csv":
                resposta = self._responder_csv(pergunta, df, sistema_prompt)
            elif tipo_resposta == "pdf":
                resposta = self._responder_pdf(pergunta, contexto_pdf, sistema_prompt)
            elif tipo_resposta == "consolidada":
                resposta = self._responder_consolidado(pergunta, df, contexto_pdf, sistema_prompt)
            
            # ‚ú® SALVA CONVERSA NA MEM√ìRIA AUTOMATICAMENTE
            self.memoria.salvar_contexto(
                pergunta=pergunta,
                resposta=resposta,
                metadados_extras={
                    "tipo_resposta": tipo_resposta,
                    "tem_csv": tem_csv,
                    "tem_pdf": tem_pdf
                }
            )
            logger.info("üíæ Conversa salva na mem√≥ria inteligente")
            
            return resposta

        except Exception as e:
            logger.error(f"Erro ao gerar resposta: {e}")
            return f"Erro ao processar pergunta: {str(e)}"

    # ‚úÖ ADICIONE OS M√âTODOS _responder_*
    
    def _responder_csv(self, pergunta, df, sistema_prompt):
        """Responde usando APENAS dados estruturados - VERS√ÉO CORRIGIDA"""
        logger.info("üìä Modo: Dados Estruturados")
        
        try:
            tem_nfe = any(col.startswith('emit_') for col in df.columns)
            tem_nfse = any(col.startswith('prestador_') for col in df.columns)
            
            dados_json = df.head(50).to_json(orient='records', force_ascii=False, indent=2)
            
            total_registros = len(df)
            resumo_colunas = ", ".join(df.columns.tolist())
            
            colunas_valor = [col for col in df.columns if 'valor' in col.lower() or 'total' in col.lower()]
            estatisticas = ""
            if colunas_valor:
                for col in colunas_valor:
                    if pd.api.types.is_numeric_dtype(df[col]):
                        try:
                            estatisticas += f"\n{col}: Soma={df[col].sum():.2f}, M√©dia={df[col].mean():.2f}, Min={df[col].min():.2f}, Max={df[col].max():.2f}"
                        except:
                            pass
            
            contexto_estrutural = f"""
üìä ESTRUTURA DOS DADOS:
- Total de registros: {total_registros}
- Total de campos: {len(df.columns)}
"""
            
            if tem_nfe:
                contexto_estrutural += "üîµ **Cont√©m NF-e (Nota Fiscal Eletr√¥nica)**\n"
            
            if tem_nfse:
                contexto_estrutural += "üü£ **Cont√©m NFS-e (Nota Fiscal de Servi√ßo)**\n"
            
            template_usuario = """
{contexto_estrutural}

üìã COLUNAS DISPON√çVEIS:
{resumo_colunas}

üìà ESTAT√çSTICAS:
{estatisticas}

üìÑ REGISTROS COMPLETOS (JSON):
{dados_json}

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üîç PERGUNTA DO USU√ÅRIO: {pergunta}

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
INSTRU√á√ïES CR√çTICAS:
1. Use APENAS os dados JSON acima para responder
2. Cite valores EXATOS dos registros JSON
3. Se a pergunta menciona "prestador", "tomador", "emitente", "destinat√°rio": busque nos campos correspondentes do JSON
4. Para perguntas sobre valores: use as estat√≠sticas e dados JSON
5. Para perguntas sobre quantidade: use total_registros
6. Responda de forma direta e natural
7. N√ÉO invente dados - use apenas o que est√° no JSON
8. Se n√£o encontrar no JSON, diga claramente que o dado n√£o est√° dispon√≠vel
"""
            
            human_prompt = HumanMessagePromptTemplate.from_template(template_usuario)
            chat_prompt = ChatPromptTemplate.from_messages([sistema_prompt, human_prompt])

            chain = (
                RunnablePassthrough.assign(
                    contexto_estrutural=lambda x: contexto_estrutural,
                    resumo_colunas=lambda x: resumo_colunas,
                    estatisticas=lambda x: estatisticas if estatisticas else "Nenhuma coluna num√©rica de valor encontrada",
                    dados_json=lambda x: dados_json,
                    pergunta=lambda x: x["pergunta"]
                )
                | chat_prompt
                | self.llm
                | StrOutputParser()
            )

            resposta = chain.invoke({"pergunta": pergunta})
            resposta = re.sub(r'<[^>]+>', '', resposta)
            resposta = resposta.strip()
            
            if not resposta or len(resposta) < 10:
                resposta = "Desculpe, n√£o consegui processar sua pergunta com os dados dispon√≠veis."
            
            logger.info("‚úÖ Resposta gerada com sucesso")
            return resposta

        except Exception as e:
            logger.error(f"Erro ao responder: {e}")
            return f"Erro ao processar consulta: {str(e)}"

    def _responder_pdf(self, pergunta, contexto_pdf, sistema_prompt):
        """Responde usando APENAS documentos PDF"""
        logger.info("üìÑ Modo: PDF")
        
        try:
            template_usuario = """
üìÑ CONTEXTO DO DOCUMENTO PDF
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
{contexto_pdf}

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
PERGUNTA: {pergunta}

INSTRU√á√ïES:
- Use APENAS as informa√ß√µes do documento acima
- Responda de forma direta
- N√£o mencione "segundo o PDF" ou "no documento"
- Se n√£o encontrar, diga claramente
- Sem tags HTML
"""
            
            human_prompt = HumanMessagePromptTemplate.from_template(template_usuario)
            chat_prompt = ChatPromptTemplate.from_messages([sistema_prompt, human_prompt])

            chain = (
                RunnablePassthrough.assign(
                    contexto_pdf=lambda x: contexto_pdf,
                    pergunta=lambda x: x["pergunta"]
                )
                | chat_prompt
                | self.llm
                | StrOutputParser()
            )

            resposta = chain.invoke({"pergunta": pergunta})
            resposta = re.sub(r'<[^>]+>', '', resposta)
            resposta = resposta.strip()
            
            logger.info("‚úÖ Resposta PDF gerada")
            return resposta

        except Exception as e:
            logger.error(f"Erro ao responder PDF: {e}")
            return f"Erro ao analisar documento: {str(e)}"

    def _responder_consolidado(self, pergunta, df, contexto_pdf, sistema_prompt):
        """Responde usando DADOS + PDFs juntos"""
        logger.info("üîÄ Modo: Consolidado")
        
        try:
            tem_nfe = any(col.startswith('emit_') for col in df.columns)
            tem_nfse = any(col.startswith('prestador_') for col in df.columns)
            
            contexto_estrutural = f"Total de registros: {len(df)}\n"
            if tem_nfe:
                contexto_estrutural += "üîµ Cont√©m NF-e\n"
            if tem_nfse:
                contexto_estrutural += "üü£ Cont√©m NFS-e\n"
            
            colunas_originais = df.columns.tolist()
            colunas_formatadas = [self._formatar_nome_campo(col) for col in colunas_originais[:30]]
            
            dados_json = df.head(30).to_json(orient='records', force_ascii=False, indent=2)
            
            template_usuario = """
üìä REGISTROS FISCAIS ELETR√îNICOS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
{contexto_estrutural}

Campos: {colunas}

Dados JSON:
{dados_json}

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üìÑ DOCUMENTOS FISCAIS (PDF)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
{contexto_pdf}

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
PERGUNTA: {pergunta}

INSTRU√á√ïES:
- Analise ambas as fontes
- Responda de forma integrada
- Cite origem apenas se houver discrep√¢ncia
- Sem tags HTML
"""
            
            human_prompt = HumanMessagePromptTemplate.from_template(template_usuario)
            chat_prompt = ChatPromptTemplate.from_messages([sistema_prompt, human_prompt])

            chain = (
                RunnablePassthrough.assign(
                    contexto_estrutural=lambda x: contexto_estrutural,
                    colunas=lambda x: ", ".join(colunas_formatadas),
                    dados_json=lambda x: dados_json,
                    contexto_pdf=lambda x: contexto_pdf[:1500],
                    pergunta=lambda x: x["pergunta"]
                )
                | chat_prompt
                | self.llm
                | StrOutputParser()
            )

            resposta = chain.invoke({"pergunta": pergunta})
            resposta = re.sub(r'<[^>]+>', '', resposta)
            resposta = resposta.strip()
            
            logger.info("‚úÖ Resposta consolidada gerada")
            return resposta

        except Exception as e:
            logger.error(f"Erro ao responder consolidado: {e}")
            return f"Erro ao analisar dados consolidados: {str(e)}"


# ‚ú® INST√ÇNCIA GLOBAL COM MEM√ìRIA
try:
    llm_inteligente = LLMInteligente()
    logger.info("‚úÖ Inst√¢ncia LLMInteligente criada com mem√≥ria")
except Exception as e:
    logger.error(f"‚ùå Falha ao inicializar LLM: {e}")
    llm_inteligente = None


def gerar_resposta_llm(pergunta, df=None, contexto_pdf=None, historico=None):
    """
    Wrapper compat√≠vel - üß† AGORA COM MEM√ìRIA AUTOM√ÅTICA
    O par√¢metro 'historico' n√£o √© mais necess√°rio (mantido por compatibilidade)
    """
    if llm_inteligente is None:
        return "Erro: LLM n√£o foi inicializado"

    # O hist√≥rico agora √© gerenciado automaticamente pela MemoriaInteligente
    return llm_inteligente.gerar_resposta_llm(pergunta, df, contexto_pdf)
